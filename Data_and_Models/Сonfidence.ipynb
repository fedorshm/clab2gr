{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7563f4f0-8c57-4094-8a1c-6b5b7e08b10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x768 3 paragraphs, 1 picture, 1 footer, 1 footnote, 287.3ms\n",
      "Speed: 24.7ms preprocess, 287.3ms inference, 1.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 5 paragraphs, 1 picture, 1 table_signature, 1 marked_list, 1 footer, 235.0ms\n",
      "Speed: 8.3ms preprocess, 235.0ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 4 paragraphs, 1 table, 1 picture, 3 numbered_lists, 1 footer, 261.6ms\n",
      "Speed: 0.0ms preprocess, 261.6ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 4 paragraphs, 1 table, 1 footer, 1 footnote, 262.8ms\n",
      "Speed: 19.4ms preprocess, 262.8ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 4 paragraphs, 2 pictures, 1 numbered_list, 1 footer, 267.2ms\n",
      "Speed: 0.0ms preprocess, 267.2ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 5 paragraphs, 2 pictures, 1 footer, 356.9ms\n",
      "Speed: 22.3ms preprocess, 356.9ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 3 paragraphs, 1 picture, 1 numbered_list, 1 footer, 312.4ms\n",
      "Speed: 13.1ms preprocess, 312.4ms inference, 1.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 4 paragraphs, 1 picture, 1 numbered_list, 1 footer, 251.3ms\n",
      "Speed: 0.0ms preprocess, 251.3ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 4 paragraphs, 1 marked_list, 1 footer, 268.3ms\n",
      "Speed: 15.7ms preprocess, 268.3ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 2 paragraphs, 1 marked_list, 1 footer, 236.7ms\n",
      "Speed: 15.6ms preprocess, 236.7ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 2 paragraphs, 1 footer, 224.8ms\n",
      "Speed: 11.5ms preprocess, 224.8ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 paragraph, 1 footer, 235.1ms\n",
      "Speed: 7.5ms preprocess, 235.1ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 2 titles, 1 paragraph, 2 tables, 1 footer, 255.1ms\n",
      "Speed: 11.1ms preprocess, 255.1ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 1 paragraph, 1 table, 1 footer, 1 footnote, 251.8ms\n",
      "Speed: 15.6ms preprocess, 251.8ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 2 titles, 2 paragraphs, 1 table, 1 picture, 1 footer, 1 footnote, 251.1ms\n",
      "Speed: 15.6ms preprocess, 251.1ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 5 titles, 1 paragraph, 1 table, 1 footer, 267.5ms\n",
      "Speed: 7.6ms preprocess, 267.5ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 3 paragraphs, 1 picture, 1 footer, 250.7ms\n",
      "Speed: 0.0ms preprocess, 250.7ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 1 table, 1 numbered_list, 1 footer, 1 footnote, 251.7ms\n",
      "Speed: 15.7ms preprocess, 251.7ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 2 paragraphs, 1 table, 1 footer, 252.5ms\n",
      "Speed: 15.6ms preprocess, 252.5ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 paragraph, 1 picture, 1 numbered_list, 1 footer, 255.3ms\n",
      "Speed: 15.7ms preprocess, 255.3ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 paragraph, 1 numbered_list, 1 footer, 254.7ms\n",
      "Speed: 4.4ms preprocess, 254.7ms inference, 4.2ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 2 paragraphs, 1 picture, 1 numbered_list, 1 footer, 282.8ms\n",
      "Speed: 15.6ms preprocess, 282.8ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 2 tables, 1 picture, 1 marked_list, 1 footer, 1 footnote, 250.5ms\n",
      "Speed: 15.6ms preprocess, 250.5ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 paragraph, 1 table, 1 numbered_list, 1 footer, 235.7ms\n",
      "Speed: 15.6ms preprocess, 235.7ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 paragraph, 2 marked_lists, 1 footer, 1 footnote, 283.0ms\n",
      "Speed: 15.6ms preprocess, 283.0ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 3 paragraphs, 1 picture, 1 footer, 237.0ms\n",
      "Speed: 15.6ms preprocess, 237.0ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 2 paragraphs, 1 picture, 1 footer, 1 footnote, 220.1ms\n",
      "Speed: 0.0ms preprocess, 220.1ms inference, 15.7ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 1 title, 1 table, 1 footer, 307.8ms\n",
      "Speed: 0.0ms preprocess, 307.8ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 768)\n",
      "\n",
      "0: 960x768 2 titles, 1 table, 1 footer, 300.5ms\n",
      "Speed: 15.6ms preprocess, 300.5ms inference, 11.9ms postprocess per image at shape (1, 3, 960, 768)\n",
      "Обработанный PDF сохранён в C:\\Users\\Vito\\Jupyter\\Генератор\\annotated_document2.pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# Пути\n",
    "pdf_path = \"C:\\\\Users\\\\Vito\\\\Jupyter\\\\Генератор\\\\2404.19737v1.pdf\"  # Исходный PDF\n",
    "output_dir = \"C:\\\\Users\\\\Vito\\\\Jupyter\\\\Генератор\\\\Новая папка\"  # Папка для сохранения изображений\n",
    "output_pdf_path = \"C:\\\\Users\\\\Vito\\\\Jupyter\\\\Генератор\\\\annotated_document1.pdf\"  # Итоговый PDF\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Загружаем модель YOLO\n",
    "model = YOLO(\"C:\\\\Users\\\\Vito\\\\Jupyter\\\\Models\\\\runs YOLO11s datasetv3 aug imgsz=960\\\\detect\\\\train\\\\weights\\\\best.pt\")\n",
    "\n",
    "# 1. Конвертируем PDF в изображения\n",
    "pdf_document = fitz.open(pdf_path)\n",
    "image_paths = []\n",
    "\n",
    "for page_number in range(len(pdf_document)):\n",
    "    # Извлекаем страницу как изображение\n",
    "    page = pdf_document[page_number]\n",
    "    pix = page.get_pixmap(dpi=300)  # Указываем качество изображения (300 DPI)\n",
    "    image_path = os.path.join(output_dir, f\"page_{page_number + 1}.png\")\n",
    "    pix.save(image_path)\n",
    "    image_paths.append(image_path)\n",
    "\n",
    "pdf_document.close()\n",
    "\n",
    "# Настройка кастомных порогов для каждого класса\n",
    "custom_confidences = {\n",
    "    0: 0.3,  # title\n",
    "    1: 0.1,  # paragraph\n",
    "    9: 0.15, # footer\n",
    "    11: 0.1,  # formula\n",
    "    10: 0.88, # footnote\n",
    "    6: 0.9, # numbered_list\n",
    "    7: 0.9 # marked_list\n",
    "}\n",
    "\n",
    "# 2. Обрабатываем изображения моделью YOLO и визуализируем предсказания с кастомными порогами\n",
    "annotated_images = []\n",
    "for image_path in image_paths:\n",
    "    # Читаем изображение\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Применяем модель YOLO\n",
    "    results = model.predict(source=img, conf=0.4, iou=0.51, save=False)\n",
    "    \n",
    "    # Фильтруем предсказания на основе кастомных порогов для классов\n",
    "    filtered_boxes = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls = int(box.cls)  # Класс объекта\n",
    "            conf = float(box.conf)  # Уверенность объекта\n",
    "\n",
    "            # Проверяем, превышает ли уверенность кастомный порог для данного класса\n",
    "            if cls in custom_confidences:\n",
    "                if conf >= custom_confidences[cls]:\n",
    "                    filtered_boxes.append(box)\n",
    "            else:\n",
    "                # Используем общий порог (например, 0.4) для классов, для которых не задан кастомный порог\n",
    "                if conf >= 0.4:\n",
    "                    filtered_boxes.append(box)\n",
    "\n",
    "        # Применяем отфильтрованные боксы для визуализации\n",
    "        result.boxes = filtered_boxes\n",
    "\n",
    "    # Наносим рамки на изображение\n",
    "    annotated_img = results[0].plot()  # Визуализируем предсказания (аннотированное изображение)\n",
    "    annotated_image_path = image_path.replace(\".png\", \"_annotated.png\")\n",
    "    cv2.imwrite(annotated_image_path, annotated_img)\n",
    "    annotated_images.append(annotated_image_path)\n",
    "\n",
    "# 3. Преобразуем аннотированные изображения обратно в PDF\n",
    "images = [Image.open(img).convert(\"RGB\") for img in annotated_images]\n",
    "images[0].save(output_pdf_path, save_all=True, append_images=images[1:])\n",
    "\n",
    "print(f\"Обработанный PDF сохранён в {output_pdf_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
